# services/analysis_service.py
import os

from sqlalchemy import select, func, desc, or_
from database import AsyncSessionLocal
from models import TitleBasics, TitleRatings
# å¼•å…¥ Hugging Face çš„ Pipeline
from transformers import pipeline
import functools

MOOD_MAP = {
    'ğŸ˜„ å¼€å¿ƒ': ['Comedy', 'Animation', 'Family', 'Musical'],
    'ğŸ˜­ éš¾è¿‡': ['Drama', 'Romance'],
    'ğŸ˜¤ æ„¤æ€’': ['Action', 'War', 'Crime'],
    'ğŸ˜¨ å®³æ€•': ['Horror', 'Thriller', 'Mystery'],
    'ğŸ˜ åˆºæ¿€': ['Action', 'Adventure', 'Sci-Fi'],
    'ğŸ§˜ å¹³é™': ['Documentary', 'Biography', 'History'],
    'ğŸ¤” çƒ§è„‘': ['Mystery', 'Sci-Fi', 'Crime']
}

BASE_DIR = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
LOCAL_MODEL_PATH = os.path.join(BASE_DIR, "ml_models", "chinese_xlm_xnli")

@functools.lru_cache(maxsize=1)
def get_nlp_classifier():
    print(f"ğŸ“‚ [NLP] æ­£åœ¨åŠ è½½æœ¬åœ°æ¨¡å‹: {LOCAL_MODEL_PATH}")

    # æ£€æŸ¥ pytorch_model.bin æ˜¯å¦å­˜åœ¨ (è¿™æ˜¯åˆ¤æ–­ä¸‹è½½æ˜¯å¦æˆåŠŸçš„å…³é”®)
    if not os.path.exists(os.path.join(LOCAL_MODEL_PATH, 'pytorch_model.bin')):
        print("âŒ æœªæ‰¾åˆ°æ¨¡å‹æ–‡ä»¶ï¼è¯·ç¡®è®¤è·¯å¾„æ­£ç¡®ã€‚")
        return None

    try:
        # åŠ è½½æ¨¡å‹
        classifier = pipeline("zero-shot-classification", model=LOCAL_MODEL_PATH, tokenizer=LOCAL_MODEL_PATH)
        print("âœ… [NLP] æ¨¡å‹åŠ è½½å®Œæˆï¼")
        return classifier
    except Exception as e:
        print(f"âŒ [NLP] æ¨¡å‹åŠ è½½å¤±è´¥: {e}")
        return None


def analyze_text_mood(text: str):
    """
    ã€æ·±åº¦å­¦ä¹ ç®—æ³•ã€‘ä½¿ç”¨ Transformer è¿›è¡Œé›¶æ ·æœ¬æ„å›¾è¯†åˆ«
    """
    if not text or len(text.strip()) < 2:
        return None

    try:
        # 1. è·å–æ¨¡å‹
        classifier = get_nlp_classifier()

        # 2. å®šä¹‰æˆ‘ä»¬çš„å€™é€‰æ ‡ç­¾ (å»æ‰emojiï¼Œåªè¦æ–‡å­—éƒ¨åˆ†ç»™AIç†è§£)
        # MOOD_MAP.keys() æ˜¯ç±»ä¼¼ 'ğŸ˜„ å¼€å¿ƒ'ï¼Œæˆ‘ä»¬åªå– 'å¼€å¿ƒ'
        labels_map = {k.split(' ')[1]: k for k in MOOD_MAP.keys()}
        candidate_labels = list(labels_map.keys())  # ['å¼€å¿ƒ', 'éš¾è¿‡', 'æ„¤æ€’'...]

        # 3. è®© AI è¿›è¡Œé¢„æµ‹
        # multi_label=False è¡¨ç¤ºå¿…é¡»è¦é€‰å‡ºä¸€ä¸ªæœ€åƒçš„
        result = classifier(text, candidate_labels, multi_label=False)

        # 4. è§£æç»“æœ
        # result æ ¼å¼: {'labels': ['éš¾è¿‡', 'æ„¤æ€’'...], 'scores': [0.95, 0.02...]}
        top_label = result['labels'][0]
        top_score = result['scores'][0]

        print(f"ğŸ¤– AI åˆ†æç»“æœ: '{text}' -> {top_label} (ç½®ä¿¡åº¦: {top_score:.2f})")

        # è®¾ç½®ä¸€ä¸ªé˜ˆå€¼ï¼Œå¦‚æœ AI éƒ½ä¸å¤ªç¡®å®šï¼ˆæ¯”å¦‚ç½®ä¿¡åº¦ä½äº 0.3ï¼‰ï¼Œå°±è¿”å› None
        if top_score < 0.3:
            return None

        # 5. è¿”å›å¸¦ Emoji çš„å®Œæ•´ Key (ä¾‹å¦‚ 'ğŸ˜­ éš¾è¿‡')
        return labels_map.get(top_label)

    except Exception as e:
        print(f"âŒ æ¨¡å‹æ¨ç†å¤±è´¥: {e}")
        # é™çº§ç­–ç•¥ï¼šå¦‚æœæ¨¡å‹æŒ‚äº†ï¼Œå¯ä»¥ç”¨å›ç®€å•çš„å…³é”®è¯åŒ¹é…ï¼Œæˆ–è€…ç›´æ¥è¿”å› None
        return None

async def get_movies_by_mood(mood_key: str, limit=12):
    """
    æ ¹æ®å¿ƒæƒ…æ¨èç”µå½±
    åŸç†ï¼šå¿ƒæƒ… -> æ˜ å°„ä¸º Genre -> æŸ¥åº“
    """
    target_genres = MOOD_MAP.get(mood_key, [])
    if not target_genres:
        return []

    async with AsyncSessionLocal() as db:
        # æ„é€ æŸ¥è¯¢ï¼šç­›é€‰å‡ºåŒ…å«ç›®æ ‡ç±»å‹ä¹‹ä¸€çš„ç”µå½±
        # ä¸” è¯„åˆ†äººæ•° > 5000 (ä¿è¯è´¨é‡)ï¼ŒæŒ‰è¯„åˆ†å€’åº
        conditions = [TitleBasics.genres.ilike(f"%{g}%") for g in target_genres]

        query = (
            select(TitleBasics.primaryTitle, TitleRatings.averageRating, TitleBasics.genres, TitleBasics.startYear,
                   TitleBasics.tconst)
            .join(TitleRatings, TitleBasics.tconst == TitleRatings.tconst)
            .where(or_(*conditions))  # åªè¦æ»¡è¶³å…¶ä¸­ä¸€ä¸ªç±»å‹å³å¯
            .where(TitleRatings.numVotes > 5000)  # è¿‡æ»¤æ‰å¤ªå†·é—¨çš„
            .order_by(desc(TitleRatings.averageRating))  # æŒ‰é«˜åˆ†æ’åº
            .limit(limit)
        )

        # ä¸ºäº†å¢åŠ è¶£å‘³æ€§ï¼Œå…¶å®è¿™é‡Œå¯ä»¥åŠ éšæœºæ•° (func.random())ï¼Œä½†ä¸ºäº†æ€§èƒ½å…ˆæŒ‰é«˜åˆ†æ’

        result = await db.execute(query)
        # è¿”å›ç»“æœè½¬ä¸ºå­—å…¸åˆ—è¡¨ï¼Œæ–¹ä¾¿å‰ç«¯ä½¿ç”¨
        movies = []
        for row in result.all():
            movies.append({
                'primaryTitle': row.primaryTitle,
                'averageRating': row.averageRating,
                'genres': row.genres,
                'startYear': row.startYear,
                'tconst': row.tconst
            })
        return movies


async def get_top_movies(limit=10):
    """æŸ¥è¯¢è¯„åˆ†æœ€é«˜çš„Néƒ¨ç”µå½± (éœ€æœ‰è¯„åˆ†æ•°æ®)"""
    async with AsyncSessionLocal() as db:
        query = (
            select(TitleBasics.primaryTitle, TitleRatings.averageRating)
            .join(TitleRatings, TitleBasics.tconst == TitleRatings.tconst)
            .where(TitleRatings.numVotes > 10000)
            .order_by(desc(TitleRatings.averageRating))
            .limit(limit)
        )
        result = await db.execute(query)
        return result.all()

async def get_year_stats(limit=20):
    """ç»Ÿè®¡è¿‘ N å¹´çš„å½±è§†äº§é‡åˆ†å¸ƒ"""
    async with AsyncSessionLocal() as db:
        query = (
            select(TitleBasics.startYear, func.count(TitleBasics.tconst))
            .where(TitleBasics.titleType.in_(['movie', 'tvSeries', 'tvMiniSeries', 'tvMovie']))
            .where(TitleBasics.startYear.is_not(None))
            .group_by(TitleBasics.startYear)
            .order_by(desc(TitleBasics.startYear))
            .limit(limit)
        )
        result = await db.execute(query)
        return result.all()

async def get_stats_summary():
    """è·å–æ€»æ•°å’Œå¹³å‡åˆ†æ¦‚è§ˆ"""
    async with AsyncSessionLocal() as db:
        movie_count = await db.execute(select(func.count(TitleBasics.tconst)))
        avg_rating = await db.execute(select(func.avg(TitleRatings.averageRating)))
        return movie_count.scalar(), round(avg_rating.scalar() or 0, 2)