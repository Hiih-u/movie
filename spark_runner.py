# import sys
# import os
# import pandas as pd
# from sqlalchemy import create_engine, text
# from pyspark.sql import SparkSession
# from pyspark.ml.recommendation import ALS
# from pyspark.sql.functions import col, explode
#
# # --- é…ç½®æ•°æ®åº“è¿æ¥ ---
# DATABASE_URL = "postgresql+psycopg2://postgresuser:password@localhost:5432/movie_db"
#
# def run_spark_job():
#     print("ğŸš€ [Step 1] åˆå§‹åŒ– Spark å¼•æ“...")
#     # å¯åŠ¨ Spark Session (é…ç½®å†…å­˜ä½¿ç”¨)
#     spark = SparkSession.builder \
#         .appName("MovieRec_ALS_Engine") \
#         .config("spark.driver.memory", "2g") \
#         .master("local[*]") \
#         .getOrCreate()
#
#     spark.sparkContext.setLogLevel("ERROR")  # å‡å°‘æ—¥å¿—å¹²æ‰°
#
#     print("ğŸ“¥ [Step 2] ä»æ•°æ®åº“åŠ è½½è¯„åˆ†æ•°æ®...")
#     # ä½¿ç”¨ Pandas è¯»å–æ•°æ®åº“ (é€‚åˆåƒä¸‡çº§ä»¥ä¸‹æ•°æ®ï¼Œè¶…å¤§æ•°æ®éœ€ç”¨ JDBC)
#     engine = create_engine(DATABASE_URL)
#
#     # è¯»å–ç”¨æˆ·è¯„åˆ†è¡¨ (user_id, tconst, rating)
#     # æ³¨æ„ï¼šALS éœ€è¦ user_id å’Œ item_id éƒ½æ˜¯æ•°å­—ï¼
#     # å¦‚æœä½ çš„ tconst æ˜¯ 'tt001' è¿™ç§å­—ç¬¦ä¸²ï¼Œæˆ‘ä»¬éœ€è¦ç”¨ StringIndexer è½¬æˆæ•°å­—ï¼Œ
#     # æˆ–è€…ä¸ºäº†ç®€å•ï¼Œè¿™é‡Œå‡è®¾æˆ‘ä»¬åªç”¨ user_id (int) å’Œ rating
#     query = "SELECT user_id, tconst, rating FROM user_personal_ratings"
#     pdf_ratings = pd.read_sql(query, engine)
#
#     if pdf_ratings.empty:
#         print("âŒ æ•°æ®åº“æ²¡æœ‰è¯„åˆ†æ•°æ®ï¼Œè¯·å…ˆç”Ÿæˆæ•°æ® (seed_ratings.py)")
#         return
#
#     # Pandas DF -> Spark DF
#     ratings_df = spark.createDataFrame(pdf_ratings)
#
#     # --- å…³é”®å¤„ç†ï¼šå› ä¸º tconst æ˜¯å­—ç¬¦ä¸²ï¼ŒALS åªèƒ½åƒæ•°å­— ---
#     # æˆ‘ä»¬éœ€è¦ç»™ tconst ç¼–ä¸ªå· (String -> Index)
#     from pyspark.ml.feature import StringIndexer
#
#     indexer = StringIndexer(inputCol="tconst", outputCol="movie_id_int")
#     indexer_model = indexer.fit(ratings_df)
#     ratings_df = indexer_model.transform(ratings_df)
#
#     print("ğŸ§  [Step 3] è¿è¡Œ ALS ååŒè¿‡æ»¤ç®—æ³•...")
#     # ALS å‚æ•°é…ç½®
#     als = ALS(
#         maxIter=10,
#         regParam=0.1,
#         userCol="user_id",
#         itemCol="movie_id_int",
#         ratingCol="rating",
#         coldStartStrategy="drop",
#         nonnegative=True
#     )
#
#     model = als.fit(ratings_df)
#
#     print("ğŸ”® [Step 4] ä¸ºæ‰€æœ‰ç”¨æˆ·ç”Ÿæˆ Top 10 æ¨è...")
#     # ç»™æ¯ä¸ªäººæ¨è 10 éƒ¨
#     user_recs = model.recommendForAllUsers(10)
#
#     # ç»“æœæ ¼å¼å¤„ç†ï¼šå°†æ•°ç»„ç‚¸å¼€ (Explode)
#     # åŸå§‹: [User: 1, Recs: [(Movie: 101, Score: 4.5), ...]]
#     # ç›®æ ‡: User: 1, Movie: 101, Score: 4.5
#     recs_exploded = user_recs.select(
#         col("user_id"),
#         explode("recommendations").alias("rec")
#     ).select(
#         col("user_id"),
#         col("rec.movie_id_int"),
#         col("rec.rating").alias("score")
#     )
#
#     # --- å°†æ•°å­— ID è½¬å› tconst å­—ç¬¦ä¸² ---
#     # åˆ©ç”¨ä¹‹å‰çš„ indexer é€†å‘è½¬æ¢
#     from pyspark.ml.feature import IndexToString
#     converter = IndexToString(inputCol="movie_id_int", outputCol="tconst", labels=indexer_model.labels)
#     final_recs = converter.transform(recs_exploded).select("user_id", "tconst", "score")
#
#     print("ğŸ’¾ [Step 5] ç»“æœå­˜å›æ•°æ®åº“ (spark_recommendations è¡¨)...")
#     # Spark DF -> Pandas DF
#     result_pdf = final_recs.toPandas()
#
#     # å†™å…¥æ•°æ®åº“ (å…ˆæ¸…ç©ºæ—§ç»“æœï¼Œå†å†™å…¥æ–°ç»“æœ)
#     with engine.connect() as conn:
#         conn.execute(text("TRUNCATE TABLE spark_recommendations"))  # æ¸…ç©º
#         conn.commit()
#
#     # æ‰¹é‡å†™å…¥
#     result_pdf.to_sql('spark_recommendations', engine, if_exists='append', index=False)
#
#     print(f"âœ… æˆåŠŸï¼å·²ä¿å­˜ {len(result_pdf)} æ¡æ¨èè®°å½•ã€‚")
#     spark.stop()
#
#
# if __name__ == "__main__":
#     run_spark_job()